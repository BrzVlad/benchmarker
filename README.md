# Mono Benchmarker

## Configuring

Each Mono configuration requires a `.conf` file.  The files in the `configs` directory are examples. The JSON structure is as follow :

    - Name : name of the config (must be unique across all configs)
    - Count : number of time to run the benchmark (optional, default : 5)
    - Mono : path to the mono executable (optional, default to system one)
    - MonoOptions : command line parameters to pass to the mono runtime (optional)
    - MonoEnvironmentVariables : environment variables to set to run the benchmark (optional)
    - ResultsDirectory : path to the results directory, relative to the benchmarker repository root directory (optional, default to results/)

## Comparing directly

To compare two or more revisions and/or configurations directly, use `tools/compare.exe`:

    ./compare.exe [parameters] [--] <tests-dir> <results-dir> <benchmarks-dir> <config-file> [<config-file>+]

Where : 
  - tests-dir : path to tests/ directory
  - results-dir : path to results/ directory
  - benchmarks-dir : path to benchmarks/ directory
  - config-file : path to a configuration file to run, there is one or more

Store the graph to "graph.svg" in current directory by default.

## JSON results format

The new JSON results format is as follow :

    - DateTime : date and time at which this benchmark was run
    - Benchmark : copy data of the `benchmarks/*.benchmark` corresponding file
      - Name : name of the benchmark
      - TestDirectory : working directory to use to run the benchmark, relative to tests/
      - CommandLine : command line parameters to pass to the benchmark
      - Timeout : timeout specific to this benchmark, in seconds
    - Config : copy data of the `configs/*.conf` corresponding file
      - Name : name of the config
      - Count : number of time to run the benchmark
      - Mono : path to the mono executable
      - MonoOptions : command line parameters to pass to the mono runtime
      - MonoEnvironmentVariables : environment variables to set to run the benchmark
      - ResultsDirectory : path to the results directory, relative to the benchmarker repository root directory
    - Version : standard output when run with `--version` runtime command line parameter
    - Runs : collections of the runs for the benchnark, size is equal to Config.Count
      - WallClockTime : wall clock time taken to run the benchmark
      - Output : standard output of the benchmark
      - Error : standard error of the benchmark
    - Timedout : true if any of the run of the benchmark has timed out

## Comparing counters

To compare counters for two or more revisions and/or configurations, you first need to run a benchmark with the log profiler enabled for each of the revision and/or configuration you want to test:

    mono --profile=log:nocalls,noalloc,counters,output=<proflog-out> benchmark.exe benchmark-args

Then use comparator/compare.exe and gnuplot to produce graphs:

    (cd comparator && mono compare.exe [--help] [-s <sections>] [-n <names>] [-c <columns>]
                                       [-h <height>] [-w <width>] <proflog-out>
									   [<proflog-out> ...] | gnuplot > graph.png)

Only Mono 3.8.0 and higher log profiler support counters sampling. If your installed Mono version is lower, you can still load a specific version of the log profiler by specifying `LD_LIBRARY_PATH="/path/to/mono-master/mono/profiler/.libs"`.

The output generated by the `compare.exe` tool is a gnuplot script, which means you need to install gnuplot first (`brew install gnuplot` on OSX).
